{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ecda245",
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
    "STEPS = 150\n",
    "FPS = 30\n",
    "FREEZE_STEPS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67dac908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad94bf808f44ee6abb6c4fa011411ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload exactly 1 file for source.\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import FileUpload\n",
    "import os\n",
    "\n",
    "uploader = FileUpload()\n",
    "display(uploader)\n",
    "\n",
    "if len(uploader.value) != 1:\n",
    "  print(\"Upload exactly 1 file for source.\")\n",
    "else:\n",
    "  for k, v in uploader.value.items():\n",
    "    _, ext = os.path.splitext(k)\n",
    "    os.remove(k)\n",
    "    SOURCE_NAME = f\"source{ext}\"\n",
    "    open(SOURCE_NAME, 'wb').write(v['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae42085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe08dd84b3e4bb4964584f1c73393c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload exactly 1 file for target.\n"
     ]
    }
   ],
   "source": [
    "uploader = FileUpload()\n",
    "display(uploader)\n",
    "\n",
    "if len(uploader.value) != 1:\n",
    "  print(\"Upload exactly 1 file for target.\")\n",
    "else:\n",
    "  for k, v in uploader.value.items():\n",
    "    _, ext = os.path.splitext(k)\n",
    "    os.remove(k)\n",
    "    TARGET_NAME = f\"target{ext}\"\n",
    "    open(TARGET_NAME, 'wb').write(v['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "844df023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-12 17:02:50--  http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2\n",
      "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
      "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5706710 (5.4M)\n",
      "Saving to: 'shape_predictor_5_face_landmarks.dat.bz2'\n",
      "\n",
      "shape_predictor_5_f 100%[===================>]   5.44M   245KB/s    in 60s     \n",
      "\n",
      "2023-07-12 17:03:51 (92.7 KB/s) - 'shape_predictor_5_face_landmarks.dat.bz2' saved [5706710/5706710]\n",
      "\n",
      "bzip2: Output file shape_predictor_5_face_landmarks.dat already exists.\n"
     ]
    }
   ],
   "source": [
    "!wget http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2\n",
    "!bzip2 -d shape_predictor_5_face_landmarks.dat.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945ab625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'stylegan2-ada-pytorch' already exists and is not an empty directory.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: ninja in /Users/jingjing/miniconda3/lib/python3.8/site-packages (1.11.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
    "!pip install ninja\n",
    "sys.path.insert(0, \"/content/stylegan2-ada-pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33923b12",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4055633075.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import site-packages/cv2\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import dlib\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_5_face_landmarks.dat')\n",
    "\n",
    "def find_eyes(img):\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  rects = detector(gray, 0)\n",
    "  \n",
    "  if len(rects) == 0:\n",
    "    raise ValueError(\"No faces detected\")\n",
    "  elif len(rects) > 1:\n",
    "    raise ValueError(\"Multiple faces detected\")\n",
    "\n",
    "  shape = predictor(gray, rects[0])\n",
    "  features = []\n",
    "\n",
    "  for i in range(0, 5):\n",
    "    features.append((i, (shape.part(i).x, shape.part(i).y)))\n",
    "\n",
    "  return (int(features[3][1][0] + features[2][1][0]) // 2, \\\n",
    "    int(features[3][1][1] + features[2][1][1]) // 2), \\\n",
    "    (int(features[1][1][0] + features[0][1][0]) // 2, \\\n",
    "    int(features[1][1][1] + features[0][1][1]) // 2)\n",
    "\n",
    "def crop_stylegan(img):\n",
    "  left_eye, right_eye = find_eyes(img)\n",
    "  d = abs(right_eye[0] - left_eye[0])\n",
    "  z = 255/d\n",
    "  ar = img.shape[0]/img.shape[1]\n",
    "  w = img.shape[1] * z\n",
    "  img2 = cv2.resize(img, (int(w), int(w*ar)))\n",
    "  bordersize = 1024\n",
    "  img3 = cv2.copyMakeBorder(\n",
    "      img2,\n",
    "      top=bordersize,\n",
    "      bottom=bordersize,\n",
    "      left=bordersize,\n",
    "      right=bordersize,\n",
    "      borderType=cv2.BORDER_REPLICATE)\n",
    "\n",
    "  left_eye2, right_eye2 = find_eyes(img3)\n",
    "\n",
    "  crop1 = left_eye2[0] - 385 \n",
    "  crop0 = left_eye2[1] - 490\n",
    "  return img3[crop0:crop0+1024,crop1:crop1+1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dfc9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
